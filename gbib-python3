#!/usr/local/bin/python3

# (c) Dec 2015, Krishnamoorthy Dinesh
# License : GPLv3

import sys, os, re
import signal
try:
    from bs4 import BeautifulSoup
except ImportError:
    print("Python BeautifulSoup parser package missing : do apt-get install python-beautifulsoup")
    sys.exit(0)
else:
    try:
        import requests
    except ImportError:
        print("Python requests package missing : do apt-get install python-requests")
        sys.exit(0)
    else:
        DBLP_BASE_URL = 'https://dblp.uni-trier.de/'
        DBLP_AUTHOR_SEARCH_URL = DBLP_BASE_URL + 'search/author'
        DBLP_TITLE_SEARCH_URL = DBLP_BASE_URL + 'search/q'
        DBLP_BIBTEX_URL= DBLP_BASE_URL + "rec/bib2/"

        def sig_handle(sig, fr):
            print ("Exit")
            sys.exit(0)

        def getbib(title_str):
            resp = requests.get(DBLP_TITLE_SEARCH_URL, params={'q':title_str})
            soup= BeautifulSoup(resp.content,features='lxml')
            l = []
            for classtag in soup.findAll('li', {'class':"select-on-click"}):
                for smalltag in classtag.findAll('small'):
                    if not re.search("dblp.org",str(smalltag.text)):
                         l.append(str(smalltag.text))
            rlen = len(l)
            if rlen == 0:
                print ("No entries found")
                return
            elif rlen == 1:
                url = DBLP_BIBTEX_URL + l[0] + ".bib"
                data = requests.get(url).content
            else:
                print ("Multiple entries detected")
                for i in range(rlen):
                    print ((i+1), ")",  l[i])
                ch = input("Enter choice (default 1) ")
                if len(ch) == 0 or not ch.isdigit():
                    v = 0
                else:
                    v = int(ch)-1
                if v > rlen-1:
                    v = 0
                url = DBLP_BIBTEX_URL + l[v] + ".bib"
                data = requests.get(url).content.decode("utf-8")

            # split response into lines 
            lines = data.splitlines()


            # Do processing of first line to get desired bibkey 
            header = re.search("\@(.*){", lines[0]).group(0)
            bibkey = re.sub("[a-z]", "", str(re.search(".*\/(.*)$", str(lines[0])).group(1)))
            print (header, bibkey)
            
            # process rest of the lines
            lines = lines[1:]

            for line in lines:
                if not re.search('crossref', line):    # ignore crossref
                    print (line)
                if line == '}':    # end of bib. Do not print crossref.
                    break

def main():
    count = len(sys.argv)
    if count == 1:
        print ("Usage :", os.path.basename(__file__), "\"Title of the paper in quotes\"")
        sys.exit(-1)

    getbib(sys.argv[1])

# for graceful exit on Ctrl+C
if __name__ == "__main__":
    signal.signal(signal.SIGINT, sig_handle)
    main()
